# scan_letters_rp4.py
import cv2
import torch
import numpy as np
import time
from picamera2 import Picamera2
import math
import os

# üîπ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
from modeln import ArmenianLetterNet

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–æ–∫
with open("labels.txt", "r", encoding="utf-8") as f:
    labels = [line.strip() for line in f.readlines()]

model = ArmenianLetterNet()
model.load_state_dict(torch.load("armenian_letters_model_improved.pth", map_location="cpu"))
model.eval()

# üîπ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏—Å—Ç–µ–º—ã
HEIGHT = 35  # –í—ã—Å–æ—Ç–∞ –ø–æ–ª—ë—Ç–∞ (30-40 –º)
CAMERA_ANGLE = 45  # –£–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –∫–∞–º–µ—Ä—ã (–≥—Ä–∞–¥—É—Å—ã)
FOV_H = 62.2  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π —É–≥–æ–ª –æ–±–∑–æ—Ä–∞ –∫–∞–º–µ—Ä—ã
FOV_V = 48.8  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —É–≥–æ–ª –æ–±–∑–æ—Ä–∞ –∫–∞–º–µ—Ä—ã
RESOLUTION = (3280, 2464)  # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã

# üîπ –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∫–∞–º–µ—Ä—ã (–≤ –º–µ—Ç—Ä–∞—Ö)
FOCAL_LENGTH = HEIGHT * math.tan(math.radians(FOV_V / 2))

# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
camera = Picamera2()
config = camera.create_preview_configuration(main={"size": RESOLUTION, "format": "RGB888"})
camera.configure(config)
camera.start()

# üîπ –§–∏–ª—å—Ç—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
confidence_threshold_low = 0.75   # üìå –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —É—á—ë—Ç–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
confidence_threshold_high = 0.85  # üìå –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–π —Å—Ä–∞–∑—É —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
frame_buffer = []  # –ë—É—Ñ–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def process_image(image):
    """ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ """
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ
        transforms.Resize((32, 32)),  # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ 32x32
        transforms.ToTensor(),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
        transforms.Normalize((0.5,), (0.5,))  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    ])
    image_tensor = transform(image).unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
    return image_tensor

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—É–∫–≤—ã
def predict_letter(image_tensor):
    """ –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –±—É–∫–≤—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ """
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        confidence, predicted_class = torch.max(probabilities, 1)
    return predicted_class.item(), confidence.item()

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–æ–Ω—Ç—É—Ä–∞ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞
def find_square_contour(image):
    """ –ù–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω—Ç—É—Ä –±–µ–ª–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ —Å —á–µ—Ä–Ω–æ–π –±—É–∫–≤–æ–π –≤–Ω—É—Ç—Ä–∏ """
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –º–æ–Ω–æ—Ö—Ä–æ–º–Ω–æ–µ (—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ)
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –±–µ–ª–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞
    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)  # –ü–æ—Ä–æ–≥ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –±–µ–ª–æ–≥–æ
    
    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã –Ω–∞ –±–∏–Ω–∞—Ä–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    for contour in contours:
        peri = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
        
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç—É—Ä –∏–º–µ–µ—Ç 4 –≤–µ—Ä—à–∏–Ω—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
        if len(approx) == 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∞—è
            area = cv2.contourArea(contour)
            if area > 1000:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –º–µ–ª–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                return approx, binary  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ç—É—Ä –∏ –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    return None, binary  # –ï—Å–ª–∏ –∫–æ–Ω—Ç—É—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞
def crop_to_contour(image, contour):
    """ –û–±—Ä–µ–∑–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–∫, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ """
    x, y, w, h = cv2.boundingRect(contour)
    cropped_image = image[y:y+h, x:x+w]
    return cropped_image

# üîπ –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–∏–∫—Å–µ–ª–µ–π –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
def pixel_to_coordinates(px, py, drone_lat, drone_lon):
    """ –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–∏–∫—Å–µ–ª–∏ –±—É–∫–≤—ã –≤ —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã """
    cx, cy = RESOLUTION[0] // 2, RESOLUTION[1] // 2  # –¶–µ–Ω—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    # üîπ –ú–µ—Ç—Ä—ã –Ω–∞ –ø–∏–∫—Å–µ–ª—å
    meters_per_pixel = (2 * HEIGHT * math.tan(math.radians(FOV_H / 2))) / RESOLUTION[0]

    # üîπ –°–º–µ—â–µ–Ω–∏–µ –±—É–∫–≤—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞ –∫–∞–º–µ—Ä—ã
    dx = (px - cx) * meters_per_pixel
    dy = (py - cy) * meters_per_pixel * math.cos(math.radians(CAMERA_ANGLE))

    # üîπ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    lat_offset = dy / 111320  # 1 –≥—Ä–∞–¥—É—Å = ~111.32 –∫–º
    lon_offset = dx / (111320 * math.cos(math.radians(drone_lat)))

    return drone_lat + lat_offset, drone_lon + lon_offset

# üîπ –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
def save_coordinates(letter, lat, lon, confidence):
    """ –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±—É–∫–≤—ã –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ SD-–∫–∞—Ä—Ç—É """
    with open("/home/pi/letters_coordinates.txt", "a") as file:
        file.write(f"{letter},{lat},{lon},{confidence:.2f}\n")

# üîπ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
def scan_letters():
    """ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–∫–≤ –∏ –∑–∞–ø–∏—Å—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç """
    global frame_buffer

    while True:
        frame = camera.capture_array("main")  # üì∑ –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–µ–º
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ –∏ –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        square_contour, binary_image = find_square_contour(frame)
        if square_contour is None:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –∫–æ–Ω—Ç—É—Ä –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.")
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫

        # –û–±—Ä–µ–∑–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–∫, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
        cropped_image = crop_to_contour(binary_image, square_contour)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PIL Image –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        cropped_image_pil = Image.fromarray(cropped_image)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –±—É–∫–≤—É
        image_tensor = process_image(cropped_image_pil)
        predicted_index, confidence_value = predict_letter(image_tensor)
        letter = labels[predicted_index]  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –≤ –±—É–∫–≤—É

        # üîπ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if confidence_value < confidence_threshold_low:
            print(f"‚ö†Ô∏è –°–ª–∞–±–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ({confidence_value:.2f}) - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º")
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∞–±—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        # üîπ –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 75-85%, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤
        if confidence_threshold_low <= confidence_value < confidence_threshold_high:
            frame_buffer.append((letter, confidence_value))

            if len(frame_buffer) >= 5:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º 5 –∫–∞–¥—Ä–æ–≤ –ø–æ–¥—Ä—è–¥
                avg_confidence = sum([c[1] for c in frame_buffer]) / len(frame_buffer)
                most_common_letter = max(set([c[0] for c in frame_buffer]), key=[c[0] for c in frame_buffer].count)
                
                if avg_confidence >= confidence_threshold_high:
                    print(f"‚úÖ –ù–∞–¥—ë–∂–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ({most_common_letter}, {avg_confidence:.2f})")
                    frame_buffer.clear()  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
                else:
                    print(f"‚ö†Ô∏è –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç ({avg_confidence:.2f}) - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    frame_buffer.clear()
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–Ω–∞–¥—ë–∂–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        # üîπ –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ 85%, –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
        if confidence_value >= confidence_threshold_high:
            drone_lat, drone_lon = 40.1792, 44.4991  # üîπ –ó–∞–≥–ª—É—à–∫–∞, –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ GPS!
            letter_lat, letter_lon = pixel_to_coordinates(RESOLUTION[0]//2, RESOLUTION[1]//2, drone_lat, drone_lon)

            save_coordinates(letter, letter_lat, letter_lon, confidence_value)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –±—É–∫–≤–∞ {letter} ({confidence_value:.2f}) –Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö {letter_lat}, {letter_lon}")

        # üîπ –≠–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ ‚Äì –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        time.sleep(2)  

# üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
scan_letters()