import cv2
import torch
import numpy as np
import time
from picamera2 import Picamera2
import math
from PIL import Image
from torchvision import transforms
import pymavlink.mavutil as mavutil
import cv2.aruco as aruco

# ðŸ”¹ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸
from modeln import ArmenianLetterNet

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼ÐµÑ‚Ð¾Ðº
with open("labels.txt", "r", encoding="utf-8") as f:
    labels = [line.strip() for line in f.readlines()]

model = ArmenianLetterNet()
model.load_state_dict(torch.load("armenian_letters_model_improved.pth", map_location="cpu"))
model.eval()

# ðŸ”¹ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÐºÐ°Ð¼ÐµÑ€Ñ‹
RESOLUTION = (3280, 2464)  # Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ ÐºÐ°Ð¼ÐµÑ€Ñ‹
camera = Picamera2()
config = camera.create_preview_configuration(main={"size": RESOLUTION, "format": "RGB888"})
camera.configure(config)
camera.start()

# ðŸ”¹ ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº MAVLink
mavlink_connection = mavutil.mavlink_connection("udp:127.0.0.1:14550")
mode = "letter"  # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ñ€ÐµÐ¶Ð¸Ð¼ Ð¿Ð¾Ð¸ÑÐºÐ° Ð±ÑƒÐºÐ²

# ðŸ”¹ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸
def process_image(image):
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),
        transforms.Resize((32, 32)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    image_tensor = transform(image).unsqueeze(0)
    return image_tensor

# ðŸ”¹ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð±ÑƒÐºÐ²Ñ‹
def predict_letter(image_tensor):
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        confidence, predicted_class = torch.max(probabilities, 1)
    return labels[predicted_class.item()], confidence.item()

# ðŸ”¹ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð½Ð°Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ñ†ÐµÐ½Ñ‚Ñ€Ð° ÐºÐ¾Ð½Ñ‚ÑƒÑ€Ð°
def get_contour_center(contour):
    M = cv2.moments(contour)
    if M["m00"] != 0:
        cx = int(M["m10"] / M["m00"])
        cy = int(M["m01"] / M["m00"])
        return cx, cy
    return None

# ðŸ”¹ Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ArUco-Ð¼Ð°Ñ€ÐºÐµÑ€Ð¾Ð²
def detect_aruco(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
    dictionary = aruco.getPredefinedDictionary(aruco.DICT_6X6_250)
    parameters = aruco.DetectorParameters()
    detector = aruco.ArucoDetector(dictionary, parameters)
    corners, ids, _ = detector.detectMarkers(gray)
    
    if ids is not None:
        for corner, marker_id in zip(corners, ids.flatten()):
            int_corners = np.int0(corner)
            cv2.polylines(frame, [int_corners], True, (0, 255, 0), 2)
            center_x = int(np.mean(corner[0][:, 0]))
            center_y = int(np.mean(corner[0][:, 1]))
            cv2.putText(frame, f"ID: {marker_id}", (center_x, center_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

# ðŸ”¹ ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð¸ÐºÐ» Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
while True:
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ MAVLink
    msg = mavlink_connection.recv_match(blocking=False)
    if msg and msg.get_type() == "COMMAND_LONG":
        if msg.command == 300:  # ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ñ€ÐµÐ¶Ð¸Ð¼Ð¾Ð²
            mode = "marker" if mode == "letter" else "letter"
            print(f"ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ¶Ð¸Ð¼Ð°: {mode}")
    
    frame = camera.capture_array("main")
    
    if mode == "letter":
        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        h, w, _ = frame.shape
        center_x, center_y = w // 2, h // 2
        
        for contour in contours:
            peri = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
            
            if len(approx) == 4 and cv2.contourArea(contour) > 1000:
                cv2.drawContours(frame, [approx], -1, (0, 255, 0), 2)
                letter_center = get_contour_center(contour)
                
                if letter_center:
                    cx, cy = letter_center
                    offset_x = cx - center_x
                    offset_y = cy - center_y
                    offset_x_percent = (offset_x / center_x) * 100
                    offset_y_percent = (offset_y / center_y) * 100
                    
                    cropped = frame[cy-16:cy+16, cx-16:cx+16]
                    cropped_pil = Image.fromarray(cropped) if cropped.shape[0] > 0 and cropped.shape[1] > 0 else None
                    
                    if cropped_pil:
                        image_tensor = process_image(cropped_pil)
                        letter, confidence = predict_letter(image_tensor)
                        
                        cv2.putText(frame, f"{letter} ({confidence:.2f})", (cx + 10, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    
                    cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)
                    cv2.putText(frame, f"X: {offset_x} px ({offset_x_percent:.2f}%)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(frame, f"Y: {offset_y} px ({offset_y_percent:.2f}%)", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    elif mode == "marker":
        detect_aruco(frame)
    
    cv2.imshow("Video Stream", frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
    
    time.sleep(2.5)

cv2.destroyAllWindows()
camera.stop()
