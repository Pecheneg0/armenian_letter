import cv2
import torch
from torchvision import transforms
from PIL import Image
import os
import time
from datetime import datetime
import logging
from modeln import ArmenianLetterNet  # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÐºÐ°Ðº Ñƒ Ñ‚ÐµÐ±Ñ)

# ==== ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ ====
SAVE_DIR = "/Users/aleksandr/Desktop/letter_test_output"
os.makedirs(SAVE_DIR, exist_ok=True)

MODEL_PATH = "/Users/aleksandr/Desktop/Ð Ð°Ð±Ð¾Ñ‚Ð°/Ð¡ÐšÐÐ¢/To_real_dron/armenian_letters_model_improved.pth"
LABELS_PATH = "/Users/aleksandr/Desktop/Ð Ð°Ð±Ð¾Ñ‚Ð°/Ð¡ÐšÐÐ¢/To_real_dron/labels.txt"
CONFIDENCE_THRESHOLD = 0.85

CAMERA_ID = 0  # 0 = Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð°Ñ ÐºÐ°Ð¼ÐµÑ€Ð°, 1 = USB-ÐºÐ°Ð¼ÐµÑ€Ð°

logging.basicConfig(
    filename=os.path.join(SAVE_DIR, "letters.log"),
    level=logging.INFO,
    format="%(asctime)s - %(message)s"
)

# ==== Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸ Ð¼ÐµÑ‚Ð¾Ðº ====
model = ArmenianLetterNet()
model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))
model.eval()

with open(LABELS_PATH, "r", encoding="utf-8") as f:
    labels = [line.strip() for line in f]

# ==== ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ====
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# ==== ÐšÐ°Ð¼ÐµÑ€Ð° ====
cap = cv2.VideoCapture(CAMERA_ID)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

print("ðŸ”¤ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ð±ÑƒÐºÐ² (Ð½Ð°Ð¶Ð¼Ð¸ 'q' Ð´Ð»Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð°)")
last_save_time = time.time()

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ ÐšÐ°Ð´Ñ€ Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½")
        continue

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    for cnt in contours:
        approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)
        area = cv2.contourArea(cnt)
        if len(approx) == 4 and area > 1000:
            x, y, w, h = cv2.boundingRect(cnt)
            letter_img = gray[y:y+h, x:x+w]
            img_pil = Image.fromarray(letter_img)
            img_tensor = transform(img_pil).unsqueeze(0)

            with torch.no_grad():
                output = model(img_tensor)
                probs = torch.nn.functional.softmax(output, dim=1)
                confidence, pred = torch.max(probs, 1)
                confidence = confidence.item()
                label = labels[pred.item()]

            if confidence > CONFIDENCE_THRESHOLD:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                log_msg = f"âœ… Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾: {label} ({confidence:.2f})"
                print(log_msg)
                logging.info(log_msg)

                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÐºÐ°Ð´Ñ€Ð° (Ñ€Ð°Ð· Ð² 10 ÑÐµÐºÑƒÐ½Ð´)
                if time.time() - last_save_time > 10:
                    filename = os.path.join(SAVE_DIR, f"letter_{timestamp}.jpg")
                    cv2.imwrite(filename, frame)
                    print(f"ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ: {filename}")
                    last_save_time = time.time()

    cv2.imshow("Letter Recognition", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
