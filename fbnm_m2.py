import cv2
import numpy as np
import torch
from torchvision import transforms
from PIL import Image
from modelold import ArmenianLetterNet
import time
import os
from datetime import datetime
from picamera2 import Picamera2
from libcamera import controls

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
MODEL_PATH = "ALM_best.pth"
LABELS_PATH = "labels.txt"
FULL_RES = (1920, 1080)
PREVIEW_RES = (640, 360)
SAVE_DIR = "/home/pi/tests/p1/p3/armenian_letters_output"
CONFIDENCE_THRESHOLD = 0.85
os.makedirs(SAVE_DIR, exist_ok=True)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===
model = ArmenianLetterNet()
state_dict = torch.load(MODEL_PATH, map_location=torch.device('cpu'))
model.load_state_dict(state_dict)
model.eval()

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–æ–∫ ===
with open(LABELS_PATH, "r", encoding="utf-8") as f:
    labels = [line.strip() for line in f.readlines()]

# === –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ===
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã ===
picam2 = Picamera2()
config = picam2.create_preview_configuration(
    main={"size": FULL_RES, "format": "RGB888"}
)
picam2.configure(config)
picam2.start()
print("üì∏ –ü–æ–∏—Å–∫ –±—É–∫–≤ –∞—Ä–º—è–Ω—Å–∫–æ–≥–æ –∞–ª—Ñ–∞–≤–∏—Ç–∞... –ù–∞–∂–º–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")

last_save_time = time.time()

while True:
    frame_rgb = picam2.capture_array()
    frame = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)

    # –°–æ–∑–¥–∞–µ–º —Ü–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∫–æ–Ω—Ç—É—Ä–æ–≤
    thresh_color = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫–æ–Ω—Ç—É—Ä—ã
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    processed_letter = None  # –ß—Ç–æ–±—ã –±—ã–ª–æ —á—Ç–æ –ø–æ–∫–∞–∑–∞—Ç—å –≤ –æ–∫–Ω–µ "Processed Letter"

    for cnt in contours:
        cv2.drawContours(thresh_color, [cnt], -1, (255, 0, 0), 2)
        area = cv2.contourArea(cnt)
        if area > 10000:
            # –ü–æ–ª—É—á–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            rect = cv2.minAreaRect(cnt)  # ((cx, cy), (w, h), angle)
            box = cv2.boxPoints(rect)
            box = np.int0(box)
            cv2.drawContours(frame, [box], 0, (0, 255, 0), 2)
            cv2.drawContours(thresh_color, [box], 0, (0, 255, 0), 2)
            
            # –í—ã—Ä–µ–∑–∞–µ–º –±—É–∫–≤—É —Å —É—á–µ—Ç–æ–º –ø–æ–≤–æ—Ä–æ—Ç–∞
            width, height = map(int, rect[1])
            if width == 0 or height == 0:
                continue  # –∏–∑–±–µ–≥–∞–µ–º –ø—É—Å—Ç—ã—Ö –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤

            src_pts = box.astype("float32")
            dst_pts = np.array([[0, height-1],
                                [0, 0],
                                [width-1, 0],
                                [width-1, height-1]], dtype="float32")
            M = cv2.getPerspectiveTransform(src_pts, dst_pts)
            letter_crop = cv2.warpPerspective(thresh_color, M, (width, height))

            # –î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            processed_letter = letter_crop.copy()

            # –ì–æ—Ç–æ–≤–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
            img_pil = Image.fromarray(letter_crop)
            img_tensor = transform(img_pil).unsqueeze(0)

            with torch.no_grad():
                output = model(img_tensor)
                probs = torch.nn.functional.softmax(output, dim=1)
                conf, pred = torch.max(probs, 1)
                conf = conf.item()
                label = pred.item()

            if conf > CONFIDENCE_THRESHOLD:
                text = f"{labels[label]} ({conf:.2f})"
                cv2.putText(frame, text, (int(rect[0][0]), int(rect[0][1])),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –±—É–∫–≤–∞: {text}")
            else:
                print(f"‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf:.2f}")


    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥
    if time.time() - last_save_time > 10:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(SAVE_DIR, f"armenian_letter_{timestamp}.jpg")
        cv2.imwrite(filename, frame)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
        last_save_time = time.time()

    # –û–∫–Ω–æ 1: –û—Å–Ω–æ–≤–Ω–æ–π –∫–∞–¥—Ä —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
    preview = cv2.resize(frame, PREVIEW_RES)
    cv2.imshow("Armenian Letters Preview", preview)

    # –û–∫–Ω–æ 2: –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–æ–Ω—Ç—É—Ä–∞–º–∏
    cv2.imshow("Threshold with Contours", thresh_color)

    # –û–∫–Ω–æ 3: –í—ã—Ä–µ–∑–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±—É–∫–≤—ã (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ)
    if processed_letter is not None:
        cv2.imshow("Processed Letter", processed_letter)
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –±—É–∫–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        empty_image = np.ones((100, 100), dtype=np.uint8) * 255
        cv2.imshow("Processed Letter", empty_image)

    # –í—ã—Ö–æ–¥ –ø–æ –∫–ª–∞–≤–∏—à–µ 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()
picam2.stop()
