# skan_letters_rp_3.py
import cv2
import torch
import numpy as np
import time
from picamera2 import Picamera2
import math
from PIL import Image
from torchvision import transforms

# üîπ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
from modeln import ArmenianLetterNet

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–æ–∫
with open("labels.txt", "r", encoding="utf-8") as f:
    labels = [line.strip() for line in f.readlines()]

model = ArmenianLetterNet()
model.load_state_dict(torch.load("armenian_letters_model_improved.pth", map_location="cpu"))
model.eval()

# üîπ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏—Å—Ç–µ–º—ã
HEIGHT = 35  # –í—ã—Å–æ—Ç–∞ –ø–æ–ª—ë—Ç–∞ (30-40 –º)
CAMERA_ANGLE = 45  # –£–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –∫–∞–º–µ—Ä—ã (–≥—Ä–∞–¥—É—Å—ã)
FOV_H = 62.2  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π —É–≥–æ–ª –æ–±–∑–æ—Ä–∞ –∫–∞–º–µ—Ä—ã
FOV_V = 48.8  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —É–≥–æ–ª –æ–±–∑–æ—Ä–∞ –∫–∞–º–µ—Ä—ã
RESOLUTION = (3280, 2464)  # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã

# üîπ –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∫–∞–º–µ—Ä—ã (–≤ –º–µ—Ç—Ä–∞—Ö)
FOCAL_LENGTH = HEIGHT * math.tan(math.radians(FOV_V / 2))

# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
camera = Picamera2()
config = camera.create_preview_configuration(main={"size": RESOLUTION, "format": "RGB888"})
camera.configure(config)
camera.start()

# üîπ –§–∏–ª—å—Ç—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
confidence_threshold_low = 0.75   # üìå –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —É—á—ë—Ç–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
confidence_threshold_high = 0.85  # üìå –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–π —Å—Ä–∞–∑—É —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
frame_buffer = []  # –ë—É—Ñ–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def process_image(image):
    """ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ """
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ
        transforms.Resize((32, 32)),  # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ 32x32
        transforms.ToTensor(),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
        transforms.Normalize((0.5,), (0.5,))  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    ])
    image_tensor = transform(image).unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
    return image_tensor

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—É–∫–≤—ã
def predict_letter(image_tensor):
    """ –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –±—É–∫–≤—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ """
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        confidence, predicted_class = torch.max(probabilities, 1)
    return predicted_class.item(), confidence.item()

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–æ–Ω—Ç—É—Ä–∞ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞
def find_square_contour(image):
    """ –ù–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω—Ç—É—Ä –±–µ–ª–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ —Å —á–µ—Ä–Ω–æ–π –±—É–∫–≤–æ–π –≤–Ω—É—Ç—Ä–∏ """
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –º–æ–Ω–æ—Ö—Ä–æ–º–Ω–æ–µ (—á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ)
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –±–µ–ª–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞
    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)  # –ü–æ—Ä–æ–≥ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –±–µ–ª–æ–≥–æ
    
    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã –Ω–∞ –±–∏–Ω–∞—Ä–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    for contour in contours:
        peri = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
        
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç—É—Ä –∏–º–µ–µ—Ç 4 –≤–µ—Ä—à–∏–Ω—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
        if len(approx) == 4:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∞—è
            area = cv2.contourArea(contour)
            if area > 1000:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –º–µ–ª–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                return approx, binary  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–Ω—Ç—É—Ä –∏ –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    return None, binary  # –ï—Å–ª–∏ –∫–æ–Ω—Ç—É—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

# üîπ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –∏ –æ–±—Ä–µ–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def align_and_crop(image, contour):
    """ –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏ –æ–±—Ä–µ–∑–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ """
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–µ—Ä—à–∏–Ω –∫–æ–Ω—Ç—É—Ä–∞
    points = contour.reshape(4, 2)
    rect = np.zeros((4, 2), dtype="float32")
    
    # –°—É–º–º–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –±—É–¥–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —É –ª–µ–≤–æ–≥–æ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É–≥–ª–∞ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —É –ø—Ä–∞–≤–æ–≥–æ –Ω–∏–∂–Ω–µ–≥–æ
    s = points.sum(axis=1)
    rect[0] = points[np.argmin(s)]  # –õ–µ–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª
    rect[2] = points[np.argmax(s)]  # –ü—Ä–∞–≤—ã–π –Ω–∏–∂–Ω–∏–π —É–≥–æ–ª
    
    # –†–∞–∑–Ω–∏—Ü–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –±—É–¥–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —É –ø—Ä–∞–≤–æ–≥–æ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É–≥–ª–∞ –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —É –ª–µ–≤–æ–≥–æ –Ω–∏–∂–Ω–µ–≥–æ
    diff = np.diff(points, axis=1)
    rect[1] = points[np.argmin(diff)]  # –ü—Ä–∞–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª
    rect[3] = points[np.argmax(diff)]  # –õ–µ–≤—ã–π –Ω–∏–∂–Ω–∏–π —É–≥–æ–ª
    
    # –í—ã—á–∏—Å–ª—è–µ–º —à–∏—Ä–∏–Ω—É –∏ –≤—ã—Å–æ—Ç—É –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞
    (tl, tr, br, bl) = rect
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    
    # –í—ã–±–∏—Ä–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —à–∏—Ä–∏–Ω—ã –∏ –≤—ã—Å–æ—Ç—ã
    maxWidth = max(int(widthA), int(widthB))
    maxHeight = max(int(heightA), int(heightB))
    
    # –¢–æ—á–∫–∏ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]], dtype="float32")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –µ—ë
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))
    
    return warped

# üîπ –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–∏–∫—Å–µ–ª–µ–π –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
def pixel_to_coordinates(px, py, drone_lat, drone_lon):
    """ –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–∏–∫—Å–µ–ª–∏ –±—É–∫–≤—ã –≤ —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã """
    cx, cy = RESOLUTION[0] // 2, RESOLUTION[1] // 2  # –¶–µ–Ω—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    # üîπ –ú–µ—Ç—Ä—ã –Ω–∞ –ø–∏–∫—Å–µ–ª—å
    meters_per_pixel = (2 * HEIGHT * math.tan(math.radians(FOV_H / 2))) / RESOLUTION[0]

    # üîπ –°–º–µ—â–µ–Ω–∏–µ –±—É–∫–≤—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞ –∫–∞–º–µ—Ä—ã
    dx = (px - cx) * meters_per_pixel
    dy = (py - cy) * meters_per_pixel * math.cos(math.radians(CAMERA_ANGLE))

    # üîπ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    lat_offset = dy / 111320  # 1 –≥—Ä–∞–¥—É—Å = ~111.32 –∫–º
    lon_offset = dx / (111320 * math.cos(math.radians(drone_lat)))

    return drone_lat + lat_offset, drone_lon + lon_offset

# üîπ –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
def save_coordinates(letter, lat, lon, confidence):
    """ –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±—É–∫–≤—ã –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ SD-–∫–∞—Ä—Ç—É """
    with open("/home/pi/letters_coordinates.txt", "a") as file:
        file.write(f"{letter},{lat},{lon},{confidence:.2f}\n")

# üîπ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
def scan_letters():
    """ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–∫–≤ –∏ –∑–∞–ø–∏—Å—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç """
    global frame_buffer

    while True:
        frame = camera.capture_array("main")  # üì∑ –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–µ–º
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ –∏ –±–∏–Ω–∞—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        square_contour, binary_image = find_square_contour(frame)
        if square_contour is None:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –∫–æ–Ω—Ç—É—Ä –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.")
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫

        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏ –æ–±—Ä–µ–∑–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        aligned_image = align_and_crop(binary_image, square_contour)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ PIL Image –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        cropped_image_pil = Image.fromarray(aligned_image)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –±—É–∫–≤—É
        image_tensor = process_image(cropped_image_pil)
        predicted_index, confidence_value = predict_letter(image_tensor)
        letter = labels[predicted_index]  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–Ω–¥–µ–∫—Å –≤ –±—É–∫–≤—É

        # üîπ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if confidence_value < confidence_threshold_low:
            print(f"‚ö†Ô∏è –°–ª–∞–±–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ({confidence_value:.2f}) - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º")
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∞–±—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        # üîπ –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 75-85%, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤
        if confidence_threshold_low <= confidence_value < confidence_threshold_high:
            frame_buffer.append((letter, confidence_value))

            if len(frame_buffer) >= 5:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º 5 –∫–∞–¥—Ä–æ–≤ –ø–æ–¥—Ä—è–¥
                avg_confidence = sum([c[1] for c in frame_buffer]) / len(frame_buffer)
                most_common_letter = max(set([c[0] for c in frame_buffer]), key=[c[0] for c in frame_buffer].count)
                
                if avg_confidence >= confidence_threshold_high:
                    print(f"‚úÖ –ù–∞–¥—ë–∂–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ({most_common_letter}, {avg_confidence:.2f})")
                    frame_buffer.clear()  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
                else:
                    print(f"‚ö†Ô∏è –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç ({avg_confidence:.2f}) - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    frame_buffer.clear()
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–Ω–∞–¥—ë–∂–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        # üîπ –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ 85%, –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
        if confidence_value >= confidence_threshold_high:
            drone_lat, drone_lon = 40.1792, 44.4991  # üîπ –ó–∞–≥–ª—É—à–∫–∞, –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ GPS!
            letter_lat, letter_lon = pixel_to_coordinates(RESOLUTION[0]//2, RESOLUTION[1]//2, drone_lat, drone_lon)

            save_coordinates(letter, letter_lat, letter_lon, confidence_value)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –±—É–∫–≤–∞ {letter} ({confidence_value:.2f}) –Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö {letter_lat}, {letter_lon}")

        # üîπ –≠–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ ‚Äì –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        time.sleep(2)  

# üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
scan_letters()